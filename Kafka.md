### Внутренняя структура данных Kafka состоит из:
1. **Event (сообщение)**, который включает в себя: ключ (key), значение (value), timestamp и опциональный набор метаданных (headers);  
1. **Topics (топики)**, в которых организованы и хранятся сообщения. В свою очередь, каждый Topic состоит из одной или более партиций;
1. **Partitions (партиции)** - это распределенный отказоустойчивый лог (Log). Сообщения с одинаковыми ключами записываются в одну и ту же партицию;
1. У каждой партиции есть один брокер лидер - **Leader** (принимает сообщения от Producer и в общем случае отдает сообщения консьюмеру); 
1. **Фолловеры (Follower)** являются брокерами, которые хранят реплику всех данных партиции и осуществляют запросы лидеру.

#### Клиентские библиотеки:
Основные способы взаимодействия с кластером.  
Официальным языком и клиентом Kafka является Java. Для других языков также создано множество библиотек.  
Все брокеры кластера могут быть помещены за один IP/Load Balancer для Service Discovery. 
При этом нужно обеспечить прямой доступ клиентов к каждому из них.  
Подробное описание протокола Apache Kafka доступно в официальной документации: https://kafka.apache.org/protocol  

#### Producer:
Посылает сообщения брокеру батчами, улучшая пропускную способность и степень сжатия данных.  
linger.ms — аналог Nagle’s Algorithm из TCP.  
Внутренний буфер ограниченного размера — buffer.memory. При заполнении блокирует отправку на max.block.ms.  
delivery.timeout.ms — общий таймаут на доставку, равный 2-м минутам по умолчанию. В пределах этого лимита клиент будет пробовать доставить сообщение заново в случае ошибок.  
При помощи опции Retries можно контролировать количество попыток доставки. Важно помнить, что Retries могут сломать очередность сообщений если max.in.flight.requests.per.connection > 1.  
 
#### Как бороться с дубликатами:
В Consumer, если у каждой записи есть внутренний ID, мы можем использовать его для атомарного сохранения результата в БД. Однако это не всегда возможно. Например, если Consumer не работает с БД со сторонним АПИ, у которого нет идемпотентности.  
При помощи настройки enable.idempotence в true: каждый Producer получает свой уникальный ID на брокере, а также инициализируется SEQ number. Producer отправляет сообщения с возрастающим SEQ, а брокер сверяет что каждое полученное сообщение обладает правильным SEQ (0,1,2,3...). Таким образом если отправляется дубликат — брокер отклоняет его, поскольку видит неправильный SEQ. Важно помнить, что используя idempotence, вы не можете выставить max.in.flight.requests.per.connection больше чем 5, а retiries в 0. Кроме того, опция acks должна быть равна all.
 

#### Consumer:
Библиотека Consumer в Kafka используется для чтения данных из топиков. Клиент Consumer автоматически обрабатывает падения брокеров и перемещения лидеров партиций в кластере.  
- enable.auto.commit — автоматические коммиты с интервалом auto.commit.interval.ms.  
- session.timeout.ms — максимальное время между heartbeat запросами к брокеру (контролируется брокером).  
- max.poll.interval.ms — максимальное время между вызовами poll (контролируется самим клиентом).  
- group.id — идентификатор группы.  
- group.instance.id — статический идентификатор консьюмера  
Рестарт должен уложиться в session.timeout.ms  
 

#### Transactions & Exactly Once:
Созданы для решения проблем обработки в “read-process-write” приложениях, где “read & write” производятся в/из Kafka.  
Традиционно выбор был из двух режимов обработки  
- at-least once — вначале мы “процессим” сообщение и затем “коммитим” оффсет в Кафку (возможна повторная обработка);
- at-most once — вначале “коммитим” оффсет и только затем “процессим” сообщение (возможна потеря данных).
- Все хотят режим exactly once — возможность обработки сообщений только 1 раз. Именно тут на помощь приходят Transactions.
 
#### Главные принципы транзакционности в Кафке:
- Атомарная запись в несколько партиций одновременно.
- Защита от “зомби” из коробки.
- Изоляция: Consumers получают сообщения только успешно завершенных транзакций.
 
“Подводные камни”, связанные с Transactions:
- Транзакционные маркеры — обычные сообщения, которые могут несколько ломать логику поиска сообщений по timestamp (offsetsByTime()), если вы пользуетесь CreateTime.
- Ущерб производительности на мелких стримах не заметен (±3% degradation, 1KB of records per/sec). Растет нагрузка на брокеры с ростом количества транзакций. Совет: использовать Transactions только там где надо (не включать по-умолчанию).
Открытые транзакции не дают Consumers с isolation.level=read_committed читать сообщения выше Last Stable Offset (LSO).  
Transactions обеспечивают exactly-once только в “read-process-write” приложениях читающих и пишущих в Кафку.  

### Как сделать кластер отказоустойчивым:
- Отказоустойчивый кластер содержит минимум 3 зукипера;
- Отказоустойчивый кластер содержит минимум 2 брокера;
- Кластер следует размещать на разных серверах;
- Сервера должны размещаться также на разных стойках.
#### Controller:
Kafka является распределенной системой, и контроллер решает задачу по координации этой системы в случае различных изменений в ее состоянии. Контроллером может стать абсолютно любой брокер в кластере.  

Контроллер отвечает за:
- За создание и удаление топиков;
- За добавление партиций и назначение им лидеров;
- За разрешение ситуаций с падениями брокеров или выходом их из кластера.

В обязанности контроллера также входит:  
- Создание новых пар
- тиций и топиков;
- Удаление топиков. 

Конфигурации брокеров, помогающие сделать кластер более отказоустойчивым:  
- auto.leader.rebalance.enable
- leader.imbalance.check.interval.seconds
- leader.imbalance.per.broker.percentage

Данная группа настроек помогает держать нагрузку на брокеры кластера равномерной (даже после рестартов и падений). Эти настройки включены по умолчанию.  
- flush.messages
- flush.ms

Данная группа настроек касается работы Kafka с подключениями.  
- max.connections
- max.connections.per.ip
- max.connection.creation.rate

Данная настройка относится, к количеству партиций лога по умолчанию (для каждого топика).  
- Num.partitions

Настройка числа партиций - не больше 4к партиций на брокер и не больше 200к партиций на кластер. Если партиций становится слишком много, то после жесткого падения ваш кластер может восстанавливаться продолжительное время (например, десятки минут). Это делает администрирование кластера более трудоемкой задачей.  
Дополнительные материалы: https://www.confluent.io/blog/apache-kafka-supports-200k-partitions-per-cluster/  
#### Бэкапы:
**Бэкапы Zookeeper являются обязательными!**  
Важно валидировать бэкапы в Zookeeper для проверки их работы (это легко и просто, поскольку бэкапы в Zookeeper легковесные).  
В случае Кафки в большинстве кейсов достаточно иметь репликацию данных (а данные уже не являются легковесными).  
Помните, что все кейсы разные, и вам нужно самостоятельно продумывать является ли оправданным или нет использование бэкапов в Kafka.  

Практики, используемые для еще большего повышения отказоустойчивости:  
- Disaster recovery plan
- Disaster тесты
- Runbooks и on-call дежурства
- Knowledge sharing и bus-factor 2+
- Разбор инцидентов

Ограничения при использовании одного Дата-центра:  
- Потеря дата-центра = stop the world;
- Физически ограниченное место для горизонтального роста;
- Не всегда можно соблюсти требования юристов.
Важно помнить, что отвечать на вопрос нужен ли вашей компании второй/третий Дата-центр должен бизнес.

#### Когда нужны несколько Дата-центров:  
- В случае, если необходимо иметь информацию наиболее географически близко к пользователю (так как расстояние может накладывать дополнительную сетевую задержку);
- Различные политические и юридические аспекты, которые могут  накладывать ограничения на вашу систему;
- Защита от различных аварий и катаклизмов в одной географической зоне;
- Расширения проекта и рост количества необходимых серверных стоек.
 
Плюсы нескольких Дата-центров:  
- Увеличение отказоустойчивости сервисов;
- Увеличение производительности сервисов;
- Возможность дальнейшего масштабирования;
- Выполнение юридических требований.

Минусы нескольких Дата-центров:  
- Увеличение стоимости инфраструктуры;
- Увеличение сложности инфраструктуры;
- Доработка существующего решения.
 
Вопросы, которые нужно задать себе при выборе нескольких Дата-центров:  
- Сколько дата-центров?
- Как близко территориально?
- Сколько нужно ресурсов? (https://eventsizer.io/)
- Какой будет сетевой трафик?
- Какой план миграции?
- Готов ли план на случай failover?
 
Преимущества Stretched кластера:  
- Синхронная репликация;
- Концептуально простой;
- Нет проблем с failover;
- Есть поддержка локального чтения.
 
Минусы, при использовании Stretched кластера:  
- Работает только при низком latency (<=30ms);
- Нет поддержки локальной записи;
- Полный отказ кластера = даунтайм.
 
Особенности асинхронного кластера:  
- Является логическим объединением нескольких физических кластеров, синхронизируемых между собой отдельной технологией, которая называется репликатор;
- Существует риск потери части данных, но работает даже при больших задержках
- Невозможно совершить failover на другой кластер, если наш основной кластер упал;
- Имеет достаточно сложную архитектуру.
 
Существующие основные репликаторы:  
- MirrorMaker
- MirrorMaker 2.0
- Uber Replicator
- Confluent Replicator
